{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Solution_LAB_Webscraping.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "zQozTBv7fkl2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LAB: Webscraping"
      ]
    },
    {
      "metadata": {
        "id": "Id8kvWq0fkl8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introducción\n",
        "\n",
        "La idea de este LAB es poder fijar algunos conceptos vistos en la clase de webscraping. Para ello, utilizando las librerias vistas en clase, haremos un análisis comparativo básico entre algunas carácterísticas de cuentos de Borges y Cortazar."
      ]
    },
    {
      "metadata": {
        "id": "x3tmXTM3fkl_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pasos a seguir:\n",
        "\n",
        "- Inspeccionar la página a consultar\n",
        "- Usar Requests para consultar la URL\n",
        "- Extraer los links relevantes para scrapear los cuentos\n",
        "- Almacenar los datos de manera conveniente\n",
        "- Utilizar los datos y Pandas para hacer alguna comparación entre los autores"
      ]
    },
    {
      "metadata": {
        "id": "dGcpBfJvfkmC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Scrapeando datos\n",
        "\n",
        "***1. Importá requests, BeautifulSoup y re***"
      ]
    },
    {
      "metadata": {
        "id": "6fduqWHGfkmE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_hL3vrddfkmW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***2. Guardá las URLS en variables*** "
      ]
    },
    {
      "metadata": {
        "id": "A512wUN7fkmY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "url_cortazar = 'https://ciudadseva.com/autor/julio-cortazar/cuentos/'\n",
        "url_borges = 'https://ciudadseva.com/autor/jorge-luis-borges/cuentos/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kQxnvBTYfkml",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***3. Hacé un pedido HTTP GET para descargar las páginas con los links*** \n",
        "***4. Usá regex para extraer los links a scrapear***\n",
        "***5. Usá BeautifulSoup para extraer los textos de esos links***\n",
        "\n",
        "Para ahorrar código considerá encapsularlo en una función!"
      ]
    },
    {
      "metadata": {
        "id": "hystQXdRfkmp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_cuentos(url):\n",
        "    titulos = []\n",
        "    textos = []\n",
        "    \n",
        "    response = requests.get(url)\n",
        "\n",
        "    for s_url in re.findall('(https://ciudadseva.com/texto/.+?/)', response.text):\n",
        "        print('Fetching:', s_url)\n",
        "        cuento = requests.get(s_url)\n",
        "        soup = BeautifulSoup(cuento.content, 'html.parser')\n",
        "\n",
        "        for elem in soup.findAll(\"div\", { \"class\" : \"text-justify\" })[:2]:\n",
        "            cuento = elem.text\n",
        "            \n",
        "        titulos.append(s_url.split('/')[-2])\n",
        "        textos.append(cuento)\n",
        "        time.sleep(np.random.randint(1,4))\n",
        "        \n",
        "    return {k:v for k,v in zip(titulos, textos)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "erlZSX9gfkm0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cuentos_bor = get_cuentos(url_borges)\n",
        "cuentos_cor = get_cuentos(url_cortazar)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9xlVzhMHiG9F",
        "colab_type": "code",
        "outputId": "8f32457f-c0df-4f83-c395-08998363a3d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "cuentos_bor"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "ADOEd29xfknK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***6. Guardalos en .csv***"
      ]
    },
    {
      "metadata": {
        "id": "Dr__4IYvfknQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_cor.to_csv(\"df_cor.csv\")\n",
        "df_cor.to_csv(\"df_bor.csv\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eDTY6UnBfkno",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***7. Cargalos a un dict o un DataFrame para hacer alguna comparación***"
      ]
    },
    {
      "metadata": {
        "id": "_kIkmhKVfkn3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_cor = pd.DataFrame.from_dict(cuentos_cor, orient=\"index\")\n",
        "df_bor = pd.DataFrame.from_dict(cuentos_bor, orient=\"index\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d53OwvdpfkoV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Bonus:\n",
        "    Usar time para dar al scraper un tiempo de espera tomado de una distibución uniforme de rango 3.\n",
        "    Usar CountVectorizer de sci-kit learn para analizar los cuentos.\n",
        "    "
      ]
    },
    {
      "metadata": {
        "id": "8pTEKgGrfkob",
        "colab_type": "code",
        "outputId": "1f829083-0090-45c6-ab9b-eca8df3ccdbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "countv_bor = CountVectorizer()\n",
        "countv_cor = CountVectorizer()\n",
        "\n",
        "countv_bor.fit(cuentos_bor)\n",
        "countv_cor.fit(cuentos_cor)\n",
        "\n",
        "df_bor = pd.DataFrame(countv_bor.transform(cuentos_bor).toarray(), columns= countv_bor.get_feature_names())\n",
        "df_cor = pd.DataFrame(countv_cor.transform(cuentos_cor).toarray(), columns= countv_cor.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-ed7377d16d8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcountv_cor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcountv_bor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcuentos_bor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mcountv_cor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcuentos_cor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m         \"\"\"\n\u001b[0;32m--> 836\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 869\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n\u001b[0m\u001b[1;32m    812\u001b[0m                                  \" contain stop words\")\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "RKSWQrewfkoy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_bor.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xiZomILJfko_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_cor.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9oZ7E3SIg5m1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}